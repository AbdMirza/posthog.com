---
title: How AI startups can deal with massive data, with Diego from Krea
date: 2025-01-25
author:
  - kevan-gilbert
showTitle: true
rootpage: /blog
sidebar: Blog
hideAnchor: true
featuredImage: >-
  
featuredImageType: full
category: Startups
---

> How AI startups can deal with massive data, with Diego from Krea.ai

The irony of going viral is that everybody wants it, but nobody’s ready for it. There is often such a sudden increase in data usage that servers strain, performance degrades and costs can shoot up for founding teams. 

Krea.ai co-founder Diego Rodriguez has surfed that wave — when his app went viral in Southeast Asia, hitting 200,000 sign-ups in a single day. Having already set up PostHog to track events for Krea, he was ready in advance for such a surge. But it’s Diego’s sense that startups usually don't need to care about big amounts of data until it’s too late — and his belief that today’s AI-driven fleet of startups are going to be dealing with more data than ever. 
His advice? If you’re building an AI-first app, you’re going to need to be ready for the massive surge of data, virality or not. Here’s how founders can prepare with a stronger foundation.

##1. AI-first apps generate more data than you can dream
Generative AI presents an entirely different paradigm for managing data such as events. “When you track user events on a finance website,” Diego says. “People don't go to a website and spend money a thousand times on a visit. That just doesn't happen. But people do come to Krea and they may make 1,000 images in a single session.” 

Diego explains:
“Let’s say your product is Canva. How much data is passing through your product? A user creates one artefact: let’s say, a poster. There it is. They’ll create one poster. You don't make many posters per second, or many posters within one minute. You make *A* poster. You work on it, and then you finish and then you save it. But in the world of AI?

For me, the equivalent of an artifact that the user made is not a poster — it’s an image that you make on the Create Image tool.  But the thing is, within one minute you can make 60 images, right? But each image is an artifact of a kind — one moment or “event” in terms of product analytics. The person is making images, but suddenly you are processing one just one even, you are processing 60, because of that image. It's almost two orders of magnitude more.”

##2. Analytics needs your full attention 
Unlike conventional apps, the data generated by apps built on generative AI will compound. Whether or not you grow users significantly, your events are always going to keep growing.

Because of the compounding effects of AI tools creating more data, and these data events compounding as you grow, if you don’t get your integrations right and test things properly, there will be significant slow-downs for your app, experienced by your users. 

As a founder, it’s true that your primary concern should be the product you’re making. But there are two other systems Diego advises you need to pay close attention to: your billing, and your analytics. “It’s not over-engineering to spend time architecting your approach to analytics,” he insists. “Analytics, at least for some time, needs your full attention.” 

Spend your time in testing analytics, and make sure they work really well. Make sure your integration is solid, so it’s not slowing you or your users down. Diego recommends:
* Spending the time managing and optimizing data ingestion
* Making sure you have efficient event management
* Paying attention to the potential impact of heavy data loads on your billing model

“Besides,” Diego brings up, “independently of what your app does, analytics is the foundation of understanding. It's one of the ways to understand your customer, and as a business owner, that is a core competency. That is industry invariant. AI or not, understanding your customer is a must. Please do not neglect analytics when integrating it.”

##3. LLM analytics are the new frontier 
Diego had one last piece of wisdom to impart: pay attention to what’s needed in the realm of LLM analytics. How are you understanding your customer’s interactions with your AI models? Are you able to keep track of the LLMs themselves? What do they perceive? How are they interacting with your business and brand? Where once customer insights were confined to the realm of “how people found your app,” we’ve now got a new frontier of “what happened in the LLM that influenced a customer?”

[PostHog has just launched a new beta tool in this category, introducing LLM observability to let you check in what took place in the deep underground pipes of your in-house agents and AI features.]
